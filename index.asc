= Atividades de processamento digital de imagens
Otávio do Espírito Santo <otavio10espsanto@gmail.com>

==  1 Primeira unidade 

== 1.1 Primeira atividade - negativo de uma região)

A primeira atividade consiste em fazer o negativo de uma imagem. Para realizar está atividade basta atribuír o valor da imagem como sendo o 255 (escala máxima do tom de cinza) menos o valor atual da imagem, isto irá inverter os tons, causando o efeito de imagem em negativo.

=== código:
[source,cpp]
----
#include <stdio.h>
#include <opencv2/opencv.hpp>

using namespace cv;

struct ponto{
	int l;
	int c;
};

int main(int argc, char **argv){
	struct ponto p1,p2;
	Mat image;

	image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
	if(!image.data)
		printf("erro ao abrir a imagem\n");

	printf("tamanho da imagem: %dx%d\n\n", image.rows, image.cols);	
	
	printf("P1:\n linha do ponto P1: ");
	scanf("%d",&p1.l);
	printf(" coluna do ponto P1: ");
	scanf("%d",&p1.c);
	printf("P2:\n linha do ponto P2: ");
	scanf("%d",&p2.l);
	printf(" coluna do ponto P2: ");
	scanf("%d",&p2.c);

	if(((p1.l || p2.l)>image.rows) || ((p1.c || p2.c)>image.cols))
		printf("ponto(s) fora da imagem!\n");
	else{
		if(p1.l <= p2.l && p1.c <= p2.c)
			for(int i=p1.l; i<p2.l; i++)
				for(int j=p1.c; j<p2.c; j++)
					image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
		else if(p1.l <= p2.l && p1.c>p2.c)
			for(int i=p1.l; i<p2.l; i++)
				for(int j=p2.c; j<p1.c; j++)
					image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
		else if(p1.l >= p2.l && p1.c <= p2.c)
			for(int i=p2.l; i < p1.l; i++)
				for(int j=p1.c; j<p2.c; j++)
					image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
		else 
			for(int i=p2.l; i<p1.l; i++)
				for(int j=p2.c; j<p1.c; j++)
					image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
	}
	imshow("janela",image);
	imwrite("../images/resultado1.png",image);
	waitKey();
}
----

=== resultado:
.resultado
image::images/resultado1.png[biel invertido]

== 1.2 Segunda atividade - inverter quadrantes 

A segunda atividade consiste na troca dos quadrantes da imagem. O primeiro e o terceiro quadrantes são trocados de posição, o primeiro fica no lugar do terceiro e vice versa, o mesmo acontece com o segundo e quarto quadrantes. No código abaixo, foram lidas duas imagens com o mesmo tamanho, a segunda imagem é o resultado da imagem carregada originalmente. Dentro do laço é realizada a operação da troca dos quadrantes, os pixels do primeiro quadrante foram copiados para a posição do terceiro e vice versa, o mesmo foi feito no segundo e quarto quadrante. No final, tem-se o resultado.

=== código:

[source, cpp]
----
#include <stdio.h>
#include <opencv2/opencv.hpp>

using namespace cv;

int main(int argc, char **argv){
	Mat image,altimage;
	image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
	altimage = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
	if(!image.data)
		printf("erro ao abrir a image\n");
	for(int i=0; i<image.rows/2; i++)
		for(int j=0; j<image.cols/2; j++){
			altimage.at<uchar>(i,j) = image.at<uchar>(image.rows/2 + i,image.cols/2 + j);
			altimage.at<uchar>(i,image.cols/2 + j) = image.at<uchar>(image.rows/2 + i,j);
			altimage.at<uchar>(image.rows/2 + i,j) = image.at<uchar>(i,image.cols/2 + j);
			altimage.at<uchar>(image.rows/2 + i,image.cols/2 + j) = image.at<uchar>(i,j);
		}
	imshow("imagem trocada", altimage);
	imwrite("../images/resultado2.png", altimage);
	waitKey();
}
----

=== resultado:
.resultado
image::images/resultado2.png[biel trocado]

== 1.3 Terceira atividade - rotulação

A terceira atividade consiste na contagem do número de objetos com bolhas que existem em uma determinada imagem. Primeiramente é feito um pré processamento para a retirada dos objetos que encostam na borda, isso é feito através do floodfill, que percorre todos os pixels da mesma cor de pixel inicial, também chamado de raíz, e os pinta de uma cor. Depois do pré processamento, aplica-se um floodfill no fundo da image, isso ajuda na diferenciação do fundo da imagem das bolhas. Depois é feito a rotulação, onde cada objeto é pintado com um tom de cinza que começa de 1 e vai até a quantidade de objetos na imagem. Por fim, percorre-se a imagem até encontrar um pixel preto, isso indica a presença de uma bolha, e aplica-se o floodfill para pintar a bolha.

=== código:
[source,cpp]
----
#include <stdio.h>
#include <opencv2/opencv.hpp>

using namespace cv;

int main(int argc, char **argv){
	Mat image;
	int obj=0,bolhas=0;
	CvPoint p;
	image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
	if(!image.data){
		printf("erro ao carregar a imagem!\n");
		return(-1);
	}

	// pré processamento para retirar os objetos das bordas
	for(int i=0; i<image.rows; i++){
		if(image.at<uchar>(i, 0) == 255){
			p.x=0;
			p.y=i;
			floodFill(image,p,0);
		}
		if(image.at<uchar>(i,image.cols - 1) == 255){
			p.x=image.cols - 1;
			p.y=i;
			floodFill(image,p,0);
		}
	}
	for(int i=0; i<image.cols; i++){
		if(image.at<uchar>(0,i) == 255){
			p.x=i;
			p.y=0;
			floodFill(image,p,0);
		}
		if(image.at<uchar>(image.rows - 1, i) == 255){
			p.x=i;
			p.y=image.rows - 1;
			floodFill(image,p,0);
		}
	}

	// muda a cor de fundo
	p.x=0;
	p.y=0;
	floodFill(image,p,254);

	// rotulação e contagem 
	for(int i=0; i<image.rows; i++)
		for(int j=0; j<image.cols; j++){
			if(image.at<uchar>(i, j) == 255){
				p.x=j;
				p.y=i;
				floodFill(image,p,++obj);
			}
			if(image.at<uchar>(i,j) == 0){
				bolhas++;
				p.x=j;
				p.y=i;
				floodFill(image,p,128);
			}
		}
	imshow("resultado",image);
	imwrite("../images/resultado3.png",image);
	printf("numero de objetos:%d\nnumero de bolhas:%d\n",obj,bolhas);	
}
----

=== resultado:
.resultado
image::images/resultado3.png[bolhas]
.resultado
image::images/resultado3,1.png[resultado]

== 1.4 Quarta atividade - histograma

=== 1.4.1 equalização

Nesta atividade é feita a equalização de uma imagem. Para isso usa-se a câmera disponível no pc para capturar a imagem. A equalização da imagem é feita através da função "equalizeHist", ela redistribui os tons da imagem de tal forma que as transições entre os tons sejam mais suaves.

=== código:
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image, gray_image, equalize_image, histGr, histEq;
  int width, height;
  VideoCapture cap;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);
  
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }
  
  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;
  Mat histImgGr(histh, histw, CV_8UC1, Scalar(0,0,0));
  Mat histImgEq(histh, histw, CV_8UC1, Scalar(0,0,0));

  while(1){
    cap >> image;
	cvtColor(image,gray_image,CV_BGR2GRAY);
	equalizeHist(gray_image,equalize_image);

    calcHist(&gray_image, 1, 0, Mat(), histGr, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&equalize_image, 1, 0, Mat(), histEq, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histGr, histGr, 0, histImgGr.rows, NORM_MINMAX, -1, Mat());
    normalize(histEq, histEq, 0, histImgEq.rows, NORM_MINMAX, -1, Mat());

    histImgGr.setTo(Scalar(0));
    histImgEq.setTo(Scalar(0));
    
    for(int i=0; i<nbins; i++){
      line(histImgGr,
           Point(i, histh),
           Point(i, histh-cvRound(histGr.at<float>(i))),
           Scalar(255), 1, 8, 0);
      line(histImgEq,
           Point(i, histh),
           Point(i, histh-cvRound(histEq.at<float>(i))),
           Scalar(255), 1, 8, 0);
    }
    histImgGr.copyTo(gray_image(Rect(0, 0       ,nbins, histh)));
    histImgEq.copyTo(equalize_image(Rect(0, histh   ,nbins, histh)));

    imshow("image", equalize_image);
	imwrite("../images/resultado4.png", equalize_image);
    if(waitKey(30) >= 0) break;
  }
  return 0;
}
----

=== resultado:
.resultado
image::images/resultado4.png[equalize]

=== 1.4.2 detector de movimentos

Nesta atividade foi implementado um detector de movimentos. Ele calcula continuamente o histograma da imagem capturada, basta usar uma das 3 componentes da imagem colorida, neste caso, foi usada a componente vermelha da imagem. É feita uma comparação do histograma atual com o anterior para que seja detectado alguma variação do mesmo. Essa comparação é feita usando-se a correlação, foi usado a função compareHist com o parâmetro CV_COMP_CORREL.

=== código:
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  int width, height;
  VideoCapture cap;
  vector<Mat> planes;
  Mat histR,histR2;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  double diff;

  cap.open(0);

  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  cap >> image;
  split (image, planes);
  calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);

  while(1){
    cap >> image;
    split (image, planes);
    calcHist(&planes[0], 1, 0, Mat(), histR2, 1,
             &nbins, &histrange,
             uniform, acummulate);
    diff = compareHist(histR,histR2,CV_COMP_CORREL);
    if(diff<0.995){
		putText(image, "MOVIMENTO DETECTADO!", Point(width/2 - 200, height/2), FONT_HERSHEY_SIMPLEX, 1, Scalar(0,0,0), 2);
    	calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             	&nbins, &histrange,
             	uniform, acummulate);
    }
	else
		putText(image, " ", Point(width/2 - 200, height/2), FONT_HERSHEY_SIMPLEX, 1, Scalar(0,0,0), 2);
    	calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             	&nbins, &histrange,
             	uniform, acummulate);
    imshow("image", image);
	waitKey(30);
  }
  return 0;
}
----

=== resultado:
image::images/resultado_motion.png[motion]
.resultado

== 1.5 Quinta atividade - laplaciano do gaussiano

Nesta atividade é feita a adição da funcionalidade lapgauss, que nada mais é que o filtro quq o laplaciano do gaussiano de uma imagem. Para isto, bastou adicionar mais um case que representa o laplgauss e seu respectivo filtro.

=== código:
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gauss\n"
    "v - vertical\n"
	"h - horizontal\n"
    "l - laplaciano\n"
	"x - lapgauss\n"
	"esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
  float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
  float horizontal[]={-1,0,1,
					  -2,0,2,
					  -1,0,1};
  float vertical[]={-1,-2,-1,
					0,0,0,
					1,2,1};
  float laplacian[]={0,-1,0,
					 -1,4,-1,
					 0,-1,0};
  float lapgauss[]={0,0,1,0,0,
  					0,1,2,1,0,
					1,2,-16,2,1,
					0,1,2,1,0,
					0,0,1,0,0};

  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  double width, height, min, max;
  int absolut;
  char key;
  
  video.open(0); 
  if(!video.isOpened()) 
    return -1;
  width=video.get(CV_CAP_PROP_FRAME_WIDTH);
  height=video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";;
  std::cout << "altura =" << height<< "\n";;

  namedWindow("filtroespacial",1);

  mask = Mat(3, 3, CV_32F, media); 
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  absolut=1; // calcs abs of the image

  menu();
  for(;;){
    video >> cap; 
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);
    filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
    if(absolut){
      frameFiltered=abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);
    imshow("filtroespacial", result);
    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
	  menu();
      absolut=!absolut;
      break;
    case 'm':
	  menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'g':
	  menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'h':
	  menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      break;
    case 'v':
	  menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      break;
    case 'l':
	  menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      break;
	case 'x':
	  menu();
	  mask = Mat(5, 5, CV_32F, lapgauss);
	  printmask(mask);
    default:
      break;
    }
  }
  return 0;
}
----

=== resultado:
.resultado
image::images/resultado5.png[filtroEspacial]

== 1.6 Sexta atividade - filtro espacial

=== 1.6.1 tiltshift

Nesta atividade foi feita o tiltshift. Basicamente, temos a superposição de duas imagens, em uma é aplicada o filtro da média e na outra temos a imagem original. É definido uma região onde é possível visualizar a imagem original e além dos limites dessa região temos a imagem borrada pelo filtro da média.

=== código
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

double alfa;
int center_slider = 0;
int center_slider_max = 100;

int alfa_slider = 0;
int alfa_slider_max = 100;

int top_slider = 0;
int top_slider_max = 100;

float media[] = {1,1,1,1,1,1,1,1,1};

Mat image1, image2, blended;
Mat imageTop;

char TrackbarName[50];

void on_trackbar_blend(int, void*){
 alfa = (double) alfa_slider/alfa_slider_max ;
 addWeighted( image1, alfa, imageTop, 1-alfa, 0.0, blended);
 imshow("addweighted", blended);
}

void on_trackbar_change(int, void*) {
    image2.copyTo(imageTop);
    Size tamanho = image2.size();
    int largura = tamanho.width;
    int altura = tamanho.height;
  int limit = top_slider*largura/100;
  int base = center_slider*largura/100;
  if(limit > 0){
    if(base >= 0 && base <= altura-limit){
  	  Mat tmp = image1(Rect(0, base, largura,limit));
  	  tmp.copyTo(imageTop(Rect(0, base, largura,limit)));
	}
	else{
  	  Mat tmp = image1(Rect(0, altura-limit, largura,limit));
  	  tmp.copyTo(imageTop(Rect(0, altura-limit, largura,limit)));
	}
  }
  on_trackbar_blend(alfa_slider,0);
}

int main(int argvc, char** argv){
  image1 = imread("../images/biel.png");
  image2 = image1.clone();
  Mat aux, mask, mask1;

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  image2.convertTo(aux, CV_32F);

  for (int i = 0; i < 10; i++) 
        filter2D(aux, aux, aux.depth(), mask, Point(1, 1), 0);    
    aux=abs(aux);
    aux.convertTo(image2, CV_8UC3);
  image1.copyTo(imageTop);
  namedWindow("addweighted", 1);

  sprintf( TrackbarName, "decaimento ");
  createTrackbar( TrackbarName, "addweighted",
				  &alfa_slider,
				  alfa_slider_max,
				  on_trackbar_blend );
  on_trackbar_blend(alfa_slider, 0 );

  sprintf( TrackbarName, "Altura ");
  createTrackbar( TrackbarName, "addweighted",
				  &top_slider,
				  top_slider_max,
				  on_trackbar_change);
  on_trackbar_change(top_slider, 0 );

  sprintf( TrackbarName, "Posição");
  createTrackbar( TrackbarName, "addweighted",
          &center_slider,
          center_slider_max,
          on_trackbar_change );

  waitKey(0);
  return 0;
}
----

=== resultado
.resultado
